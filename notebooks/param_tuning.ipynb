{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições\n",
    "Bibliotecas utilizadas e definições de path. Para facilitar a manipulação de arquivos, o diretório do projeto é definido neste ponto. Também é realizada a carga dos dados que serão utilizados neste repositório. Neste notebook, o conjunto saída do feature_engineering é o principal arquivo de trabalho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#base_path = \"C:/Users/99818854/Projetos/GitRep/adaptive_learning\"\n",
    "base_path = \"/media/bruno/Arquivos/Desenvolvimento/NextQuestion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(f\"{base_path}/data/mastery.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estratégia\n",
    "\n",
    "Uma vez que determinados o modo de calcular a maestria, falta encontrar a pontuação que será atribuída para cada acerto (geral e por dificuldade). Não sabemos ao certo como definir estes valores numéricos, porém eles possuem grande importância, seja para permitir o funcionamento do modelo quanto para interpretar os resultados. Afinal, se encontrarmos um ideal que pontua mais acertos de questões difíceis, podemos inferir que acertar questões difíceis contribui mais para a obtenção de maestria.\n",
    "\n",
    "Voltando ao ponto principal, de como obter os parâmetros de pontuação que melhor definem a maestria, podemos simplesmente testar diversos valores até achar o que melhor se adequa. É uma abordagem válida, desde que se tenham disponíveis recursos suficientes. Pensando em heurística, vamos nos contentar com um conjunto de valores bom, não necessariamente excelentes, isso já é suficiente para reduzir o tempo de busca.\n",
    "\n",
    "No lugar de simplemente chutar diversos valores ao acaso, vamos pegar emprestada a abordagem dos algoritmos genéricos, onde testandos um conjunto de parâmetros (população), selecionamos os melhores e realizamos mutações entre eles. A base deste algoritmo é uma função objetivo, resposável por dizer o quão melhor é um conjunto de parâmetros em relação à outro.\n",
    "\n",
    "Funções objetivos são o grande fino deste tipo de abordagem. Para este caso, vamos utilizar uma regressão logística, que vai receber a maestria calculada e preparar um modelo de aprendizagem de máquina responsável por dizer se, dada uma maestria e dificuldade, o respondente é capaz de acertar uma questão. Das métricas disponíveis em problemas de classificação, vamos utilizar o f1-score como resultado da função objetivo para avaliar o melhor conjunto de parâmetros.\n",
    "\n",
    "Resumindo, a partir das diversas gerações de populações arbitrárias de conjuntos de parâmetros de pontuação, vamos buscar aquele conjunto que melhor calcula a maestria que torna possível criar uma regressão logística com maior nível de eficiência. É importante pontuar que o objetivo final deste notebook não é encontrar os valores mais corretos, mas sim valores base bons, que permitam o processo de modelagem e interpretação dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(base: pd.DataFrame, params: np.array) -> Tuple[float]:\n",
    "    # Acessa apenas as fatias importantes para cálculo de maestria, computando\n",
    "    # os conjuntos de entrada (X) e resposta (y) separados em treino e teste\n",
    "    mastery = np.dot(base.values[:, 3:-1], params)\n",
    "    X, y = np.concatenate((base.values[:, 2:3], mastery), axis=1), base.values[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    # Substitui os valores nulos de dificuldade, necessárias para o modelo funcionar\n",
    "    mean_difficulty = round(np.nanmean(X_train[:, 0]))\n",
    "    X_train[np.isnan(X_train)] = mean_difficulty\n",
    "    X_test[np.isnan(X_test)] = mean_difficulty\n",
    "\n",
    "    # Execução do treinamento da função logística\n",
    "    model = SGDClassifier(loss=\"log_loss\", learning_rate=\"adaptive\", eta0=0.001)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Computação das métricas de classificação\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_params() -> List[float]:\n",
    "    # ganho | dificuldade 1 | dificuldade 2 | dificuldade 3 | dificuldade 4 | dificuldade 5\n",
    "    # Por definição, vamos manter o ganho total sempre maior do que os ganhos bônus por dificuldade\n",
    "    return [\n",
    "        np.random.random() * 4 + 1,\n",
    "        np.random.random(),\n",
    "        np.random.random(),\n",
    "        np.random.random(),\n",
    "        np.random.random(),\n",
    "        np.random.random()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(population: list) -> List[float]:\n",
    "    results = []\n",
    "    start_date = datetime.now()\n",
    "    for i in range(0, len(population)):\n",
    "        print(f\"Avaliando o indivíduo {i + 1}/{len(population)} da população...\", end=\"\\r\")\n",
    "        accuracy, precision, recall, f1 = objective_function(base, np.array(population[i]).reshape((len(population[i]), 1)))\n",
    "        results.append(f1)\n",
    "\n",
    "    end_date = datetime.now()\n",
    "    duration = round((end_date - start_date).seconds / 60, 2)\n",
    "    print(f\"Melhor F1-Score encontrado: {f1} ({duration} min)\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(population, results) -> List[float]:\n",
    "    combination = list(zip(population, results))\n",
    "    select_1 = combination[np.random.randint(0, len(combination))]\n",
    "    select_2 = combination[np.random.randint(0, len(combination))]\n",
    "    return select_1[0] if select_1[1] > select_2[1] else select_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(father, mother) -> Tuple[List[float], List[float]]:\n",
    "    element_1, element_2 = father, mother\n",
    "    if np.random.randint(0, 100) < 50:\n",
    "        point = np.random.randint(0, len(father))\n",
    "        element_1 = father[:point] + mother[point:]\n",
    "        element_2 = mother[:point] + father[point:]\n",
    "    return element_1, element_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(element):\n",
    "    for i in range(0, len(element)):\n",
    "        if np.random.randint(0, 100) < 2:\n",
    "            # Aplica a mesma regra de negócio da random_params, garantindo um\n",
    "            # valor maior para o ganho total do que o ganho por dificuldade\n",
    "            if i == 0:\n",
    "                element[i] = np.random.random() * 4 + 1\n",
    "            else:\n",
    "                element[i] = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geração primitiva:\n",
      "Melhor F1-Score encontrado: 0.782815200103661 (1.28 min)\n",
      "\n",
      "Geração 1\n",
      "Melhor F1-Score encontrado: 0.7796780297516812 (1.32 min)\n",
      "\n",
      "Geração 2\n",
      "Melhor F1-Score encontrado: 0.7821179037291381 (1.33 min)\n",
      "\n",
      "Geração 3\n",
      "Melhor F1-Score encontrado: 0.7829737504907577 (1.3 min)\n",
      "\n",
      "Geração 4\n",
      "Melhor F1-Score encontrado: 0.777426067483777 (1.35 min)\n",
      "\n",
      "Geração 5\n",
      "Melhor F1-Score encontrado: 0.7833173394969793 (1.33 min)\n",
      "\n",
      "Geração 6\n",
      "Melhor F1-Score encontrado: 0.7807695340219191 (1.35 min)\n",
      "\n",
      "Geração 7\n",
      "Melhor F1-Score encontrado: 0.780273366120561 (1.33 min)\n",
      "\n",
      "Geração 8\n",
      "Melhor F1-Score encontrado: 0.782203556663823 (1.35 min)\n",
      "\n",
      "Geração 9\n",
      "Melhor F1-Score encontrado: 0.7827858963553883 (1.35 min)\n",
      "\n",
      "Geração 10\n",
      "Melhor F1-Score encontrado: 0.776443556278078 (1.37 min)\n"
     ]
    }
   ],
   "source": [
    "# Define e inicializa os parâmetros do algoritmo genético\n",
    "generations = 10\n",
    "qntd_individuals = 10\n",
    "current_population = [random_params() for i in range(0, qntd_individuals)]\n",
    "\n",
    "print(\"Geração primitiva:\")\n",
    "current_results = evaluate(current_population)\n",
    "epochs = [list(zip(current_population, current_results))]\n",
    "\n",
    "for i in range(0, generations):\n",
    "    print(f\"\\nGeração {i + 1}\")\n",
    "    new_population = []\n",
    "\n",
    "    # Compila uma nova população a partir da geração atual\n",
    "    while len(new_population) < qntd_individuals:\n",
    "        father = select(current_population, current_results)\n",
    "        mother = select(current_population, current_results)\n",
    "        element_1, element_2 = crossover(father, mother)\n",
    "        mutate(element_1)\n",
    "        mutate(element_2)\n",
    "        new_population.append(element_1)\n",
    "        new_population.append(element_2)\n",
    "\n",
    "    # Verifica a eficiência da nova população de acordo com a função objetivo\n",
    "    current_population = new_population\n",
    "    current_results = evaluate(current_population)\n",
    "    epochs.append(list(zip(current_population, current_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretação\n",
    "\n",
    "Como comentado, para além de conseguir encontrar valores numéricos precisos, a ideia é poder interpretar o resultado a partir da comparação dos valores. Um ponto interessante deve ser comentado, que é a pontuação baixa atribuída para questões fáceis e difíceis, porém uma pontuação maior para questões intermediárias. Podemos inferir que solucionar quesões de nível médio contribuiem mais para o atingimento de maestria do que questões extremamente fáceis ou difíceis.\n",
    "\n",
    "Apesar do objetivo deste repositório não ser levantar hipóteses sobre a aprendizagem, podemos verificar numericamente que este comportamento de pontuação resulta em uma melhor acomodação da maestria dos estudantes. Assim, temos:\n",
    "\n",
    "- Ganho por cada questão acertada: 4,44 pontos\n",
    "- Ganho por cada questão nível 1 acertada: 0,33 pontos\n",
    "- Ganho por cada questão nível 2 acertada: 0,86 pontos\n",
    "- Ganho por cada questão nível 3 acertada: 0,86 pontos\n",
    "- Ganho por cada questão nível 4 acertada: 0,46 pontos\n",
    "- Ganho por cada questão nível 5 acertada: 0,39 pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros:\n",
      "[4.437959895811392, 0.3337814382791118, 0.8585858298354134, 0.8579571523067716, 0.46166699184186577, 0.38552925499586654]\n"
     ]
    }
   ],
   "source": [
    "best_f1, best_population = 0, []\n",
    "for population, f1 in zip(current_population, current_results):\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_population = population\n",
    "\n",
    "print(f\"Melhores parâmetros:\")\n",
    "print(best_population)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc00ff16b4df0209bbddf1b626f49197057a777b854bf55225ef9bf508d8a9ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
