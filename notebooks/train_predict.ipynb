{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_path = \"C:/Users/99818854/Projetos/GitRep/adaptive_learning\"\n",
    "#base_path = \"/media/bruno/Arquivos/Desenvolvimento/NextQuestion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(f\"{base_path}/data/mastery.csv\")\n",
    "submit = pd.read_csv(f\"{base_path}/data/Submit.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastery_params = [[4.44], [0.33], [0.86], [0.86], [0.46], [0.39]]\n",
    "mastery = np.dot(base.values[:, 3:-1], mastery_params)\n",
    "X, y = np.concatenate((base.values[:, 2:3], mastery), axis=1), base.values[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "mean_difficulty = round(np.nanmean(X_train[:, 0]))\n",
    "X_train[np.isnan(X_train)] = mean_difficulty\n",
    "X_test[np.isnan(X_test)] = mean_difficulty\n",
    "\n",
    "user_data = {}\n",
    "group = base.groupby([\"user_id\", \"area\"])[[\n",
    "    \"points\", \"points1\", \"points2\", \"points3\", \"points4\", \"points5\"\n",
    "]].agg(\"max\")\n",
    "\n",
    "for i in range(0, len(group)):\n",
    "    user_id, area = group.index[i]\n",
    "    if user_id not in user_data.keys():\n",
    "        user_data[user_id] = {}\n",
    "    user_data[user_id][area] = np.dot(group.values[i], mastery_params)[0]\n",
    "\n",
    "def search_mastery(user_id, area):\n",
    "    if user_id not in user_data.keys():\n",
    "        return 0\n",
    "    if area not in user_data[user_id].keys():\n",
    "        return 0\n",
    "    return user_data[user_id][area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.684545, 0.711525809084398, 0.8707648873906585, 0.783132571534639)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier(loss=\"log\", learning_rate=\"adaptive\", eta0=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>3593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>16407</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean\n",
       "predict             \n",
       "0.0       3593   0.0\n",
       "1.0      16407   1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = submit[[\"difficulty\", \"novo_user_id\", \"knowledge_area_id\"]]\n",
    "df = df.fillna(mean_difficulty)\n",
    "df[\"mastery\"] = [search_mastery(df[\"novo_user_id\"].values[i], df[\"knowledge_area_id\"].values[i]) for i in range(0, len(df))]\n",
    "\n",
    "df[\"predict\"] = model.predict(df[[\"difficulty\", \"mastery\"]].values)\n",
    "df.groupby(\"predict\")[\"predict\"].agg([\"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.713335, 0.7273828039588602, 0.8984923419532542, 0.8039336607964215)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7144083333333333,\n",
       " 0.7258686864562492,\n",
       " 0.9055587392550143,\n",
       " 0.8058179263296862)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion=\"entropy\", n_estimators=50)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_models = 15\n",
    "models: List[SGDClassifier] = []\n",
    "\n",
    "for i in range(0, total_models):\n",
    "    X_sample, y_sample = [], []\n",
    "    while len(X_sample) != len(X_train):\n",
    "        j = np.random.randint(0, len(X_train))\n",
    "        X_sample.append(X_train[j])\n",
    "        y_sample.append(y_train[j])\n",
    "\n",
    "    model = SGDClassifier(loss=\"log_loss\", learning_rate=\"adaptive\", eta0=0.001)\n",
    "    model.fit(X_sample, y_sample)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models: List[SGDClassifier], test):\n",
    "    votes = []\n",
    "    for model in models:\n",
    "        y_pred_test = model.predict(test)\n",
    "        votes.append(y_pred_test)\n",
    "\n",
    "    result = []\n",
    "    for i in range(0, len(test)):\n",
    "        total = []\n",
    "        for j in range(0, len(votes)):\n",
    "            total.append(votes[j][i])\n",
    "        predict = np.mean(total)\n",
    "        result.append(1 if predict > 0.5 else 0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, result).ravel()\n",
    "    return result, tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = []\n",
    "for model in models:\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    votes.append(y_pred_test)\n",
    "\n",
    "result = []\n",
    "for i in range(0, len(X_test)):\n",
    "    total = []\n",
    "    for j in range(0, len(votes)):\n",
    "        total.append(votes[j][i])\n",
    "    predict = np.mean(total)\n",
    "    result.append(1 if predict > 0.5 else 0)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, result).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, accuracy, precision, recall, f1 = predict(models, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74232, 132846, 55800, 337122)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy, precision, recall, f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "680323f05412a6a647162f4f4d69f1087cf97209bdf9c308c69b217830577ebd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
